% !TEX root = paper.tex

\section{Conclusion} \label{sec:conclusion}

In this work, we present a new implementation for distributed-memory NNCP that will be made publicly available.
The algorithm is general enough to handle any number of modes in the data tensor and can be adapted to use any NLS algorithm within the context of BCD (ALS).
We use a dimension tree optimization to avoid unnecessary recomputation within the bottleneck local MTTKRP computation, and we use an efficient parallelization that minimizes communication cost.
Our performance results show the ability to scale well to high processor counts, and we show favorable performance in comparison to state-of-the-art software for 3D tensors.

In particular, the performance results demonstrate that computing NNCP for dense tensors involves heavy computation relative to the sizes of the computed factor matrices.
By avoiding the communication of tensor entries and communicating only the factor matrices, the parallel algorithm is nearly always compute bound.
This observation is supported by the theoretical analysis: although the communication does not scale as well with $P$, the total amount of data depends on a sum of tensor dimensions rather the product of the tensor dimensions, which determines the total amount of computation.
For a relative comparison, consider memory-efficient parallel dense $n\times n$ matrix multiplication: the ratio of the $O(n^3/P)$ local computation to the $O(n^2/P^{1/2})$ communication is approximately the square root of the size of the local data, or $O((n^2/P)^{1/2})$.
In the case of NNCP, the ratio of local computation to communication is $O((I/P)^{1-1/N}/N)$, which is approximately the size of the local data raised to the power $1-1/N$.
This exponent is larger than $1/2$ and grows with $N$, and therefore it predicts the NNCP computation should be more computation bound than matrix multiplication.
Note that this analysis does not consider the type of local computation; for small $R$, the local computation will likely be memory bandwidth bound, but the algorithm will spend more time on local computation than on interprocessor communication.

We can also conclude from the performance results that the dimension tree optimization is the key to performance improvement over the state-of-the-art approaches.
For 3D tensors, we observe a benefit larger than the theoretical 50\% reduction in computation, and for larger numbers of modes, the improvement is only magnified.
Besides the reduction in flops, the dimension tree approach enjoys better DGEMM performance and avoids memory-bound KRP computations.
Furthermore, we see that tuning the processor grid had much less effect on overall performance.
Not only do reductions in communication not matter as much as computation, but different local tensor sizes can also cause variations in local performance that outweigh the savings in communication.

%Given an efficient parallel algorithm for NNCP, it is now possible to compare the convergence properties of various NLS algorithms on large-scale tensor data that is too large to fit on single servers or would require too much computational time to analyze interactively.
%We hope to explore this in future work.